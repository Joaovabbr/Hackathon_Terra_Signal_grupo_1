{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f00f262c-0ee8-44c6-9536-ebc9aeddfb68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, lit, when, expr\n",
    "\n",
    "# --- 1. PREPARAR BASE DE HISTÓRICO (Apenas Clientes Ativos) ---\n",
    "# Lemos a Silver para ter os dados descritivos (InternetService = 'Fiber optic')\n",
    "df_hist_silver = spark.table(\"workspace.churn_zero.history_silver\")\n",
    "\n",
    "# Filtramos apenas quem NÃO cancelou (Churn = 0 ou 'No')\n",
    "# Assumindo que na Silver o Churn é 'No' (string) ou 0 (int) dependendo da sua limpeza. \n",
    "# Ajuste o filtro abaixo se necessário.\n",
    "df_hist_active = df_hist_silver.filter(col(\"Churn\") == 0).withColumn(\"origin\", lit(\"history_active\"))\n",
    "\n",
    "# Para clientes históricos ativos, assumimos uma probabilidade de churn baixa (ou 0) \n",
    "# pois não rodamos o modelo neles agora, ou usamos o score se tiver. \n",
    "# Vamos definir 0.0 para focar o risco na base de inferência, mas manter a oportunidade de venda.\n",
    "df_hist_active = df_hist_active.withColumn(\"churn_probability\", lit(0.0))\n",
    "\n",
    "\n",
    "# --- 2. PREPARAR BASE DE INFERÊNCIA (Novos Dados com Previsão) ---\n",
    "# Lemos a tabela final de inferência que tem a probabilidade\n",
    "df_inf_pred = spark.table(\"workspace.churn_zero.inference_churn\").select(\"customerID\", \"churn_probability\", \"prediction\")\n",
    "\n",
    "# Lemos a Silver da inferência para ter os textos\n",
    "df_inf_silver = spark.table(\"workspace.churn_zero.inference_silver\")\n",
    "\n",
    "# Fazemos o Join para ter: ID + Probabilidade + Dados Descritivos\n",
    "df_inf_full = df_inf_silver.join(df_inf_pred, \"customerID\", \"inner\").withColumn(\"origin\", lit(\"inference\"))\n",
    "\n",
    "\n",
    "# --- 3. UNIFICAR AS BASES ---\n",
    "# Selecionamos as colunas comuns importantes para o Vendedor e para a IA\n",
    "common_cols = [\n",
    "    \"customerID\", \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\", \n",
    "    \"tenure\", \"PhoneService\", \"MultipleLines\", \"InternetService\", \n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \n",
    "    \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\", \n",
    "    \"PaymentMethod\", \"MonthlyCharges\", \"TotalCharges\", \n",
    "    \"feedback_topic\", \"churn_probability\", \"origin\"\n",
    "]\n",
    "\n",
    "# Garantir que ambas tenham as mesmas colunas\n",
    "df_final_base = df_hist_active.select(common_cols).unionByName(df_inf_full.select(common_cols))\n",
    "\n",
    "# Criamos uma View Temporária para usar SQL (ai_gen) na próxima célula\n",
    "df_final_base.createOrReplaceTempView(\"all_customers_view\")\n",
    "\n",
    "print(f\"Base unificada criada com {df_final_base.count()} clientes (Histórico Ativo + Inferência).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b6ce674-b18d-47b6-9f33-6c22c76288f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW customers_enriched AS\n",
    "SELECT \n",
    "    *,\n",
    "    -- Contagem de Add-ons (Importante para a regra de fidelização)\n",
    "    (CASE WHEN OnlineSecurity != 'No' THEN 1 ELSE 0 END + \n",
    "     CASE WHEN OnlineBackup != 'No' THEN 1 ELSE 0 END + \n",
    "     CASE WHEN DeviceProtection != 'No' THEN 1 ELSE 0 END + \n",
    "     CASE WHEN TechSupport != 'No' THEN 1 ELSE 0 END +\n",
    "     CASE WHEN StreamingTV != 'No' THEN 1 ELSE 0 END +\n",
    "     CASE WHEN StreamingMovies != 'No' THEN 1 ELSE 0 END) as num_addons,\n",
    "     \n",
    "    -- Classificação de Risco para o Vendedor (Visual)\n",
    "    CASE \n",
    "        WHEN churn_probability >= 0.7 THEN 'CRÍTICO'\n",
    "        WHEN churn_probability >= 0.5 THEN 'ALTO'\n",
    "        WHEN feedback_topic = 'sales_opportunity' THEN 'OPORTUNIDADE'\n",
    "        ELSE 'NORMAL'\n",
    "    END as status_venda\n",
    "FROM all_customers_view;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d479f2bc-284f-4367-89e8-f436fc8db6d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE workspace.churn_zero.app_layer_final AS\n",
    "SELECT \n",
    "    *,\n",
    "    \n",
    "    -- O CÉREBRO: Gera a instrução tática para o vendedor\n",
    "    ai_gen(\n",
    "        'Atue como um Estrategista de Vendas Sênior da Terra Signal. \n",
    "        Gere uma **Instrução Interna Curta** (máximo 25 palavras) para o vendedor que vai ligar para este cliente.\n",
    "        Seja diretivo: \"O cliente tem X, ofereça Y\".\n",
    "\n",
    "        DADOS DO CLIENTE:\n",
    "        - Risco de Churn (Probabilidade): ' || round(churn_probability * 100, 1) || '%\n",
    "        - Motivo/Feedback: ' || feedback_topic || '\n",
    "        - Tecnologia: ' || InternetService || '\n",
    "        - Valor Mensal: $' || MonthlyCharges || '\n",
    "        - Contrato: ' || Contract || '\n",
    "        - Qtd Add-ons: ' || num_addons || '\n",
    "\n",
    "        RACIOCÍNIO ESTRATÉGICO:\n",
    "        1. SE RISCO ALTO (>50%) ou FEEDBACK NEGATIVO: Foco em Retenção.\n",
    "           - Preço alto/Concorrência na Fibra -> Autorize desconto de 15% por fidelidade 1 ano.\n",
    "           - Problema Técnico (DSL/Fibra) -> Ofereça visita técnica VIP ou troca de equipamento.\n",
    "           - \"lost_sales_opportunity\" -> Win-back: ofereça exatamente o que ele queria.\n",
    "        \n",
    "        2. SE \"sales_opportunity\" (Sem Internet): \n",
    "           - Foco total em Venda Nova. Ofereça pacote Fibra com instalação grátis.\n",
    "        \n",
    "        3. SE RISCO BAIXO (Cliente Seguro): Foco em Blindagem/Upsell.\n",
    "           - Poucos Add-ons -> Ofereça TechSupport grátis por 3 meses (degustação).\n",
    "           - DSL Satisfeito -> Ofereça upgrade para Fibra com desconto.\n",
    "           - Fibra Satisfeito -> Agradeça a fidelidade (não mexa em time que está ganhando).\n",
    "\n",
    "        SAÍDA:\n",
    "        Apenas a frase da ação. Ex: \"Cliente Fibra com risco de preço. Ofereça 15% de desconto e fidelidade.\"'\n",
    "    ) as recommended_action\n",
    "\n",
    "FROM customers_enriched;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cea162b2-7b94-4453-ae15-ea0403539b14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carrega a tabela com a IA gerada\n",
    "df_app = spark.table(\"workspace.churn_zero.app_layer_final\").toPandas()\n",
    "\n",
    "# --- CÁLCULO DO PRIORITY SCORE (Para ordenar a lista no site) ---\n",
    "# Lógica: (Probabilidade Churn * Valor) + Bônus de Oportunidade\n",
    "# Queremos ligar primeiro para: \n",
    "# 1. Quem vai sair e paga muito.\n",
    "# 2. Quem quer comprar (sales_opportunity).\n",
    "\n",
    "def calculate_priority(row):\n",
    "    base_score = row['churn_probability'] * row['MonthlyCharges']\n",
    "    \n",
    "    # Bônus: Se é uma oportunidade de venda clara, joga pro topo (equivale a um risco alto)\n",
    "    if row['feedback_topic'] == 'sales_opportunity':\n",
    "        base_score += 100 # Bônus alto para vender logo\n",
    "    \n",
    "    # Bônus: Se é risco crítico de fibra (valor alto), garante prioridade\n",
    "    if row['status_venda'] == 'CRÍTICO' and row['InternetService'] == 'Fiber optic':\n",
    "        base_score *= 1.5\n",
    "        \n",
    "    return round(base_score, 2)\n",
    "\n",
    "df_app['priority_score'] = df_app.apply(calculate_priority, axis=1)\n",
    "\n",
    "# Ordenar para o site (Do maior score para o menor)\n",
    "df_app = df_app.sort_values(by='priority_score', ascending=False)\n",
    "\n",
    "# Formatar Probabilidade para % bonita\n",
    "df_app['churn_probability_display'] = (df_app['churn_probability'] * 100).round(1).astype(str) + '%'\n",
    "\n",
    "# --- SALVAR FINAL ---\n",
    "# Salva em CSV para o Streamlit ler rápido\n",
    "df_app.to_csv(\"/Workspace/Users/joaovab@al.insper.edu.br/Hackathon_Terra_Signal_grupo_1/site_data.csv\", index=False)\n",
    "\n",
    "# Salva no Unity Catalog como tabela final de consumo\n",
    "spark_final = spark.createDataFrame(df_app)\n",
    "spark_final.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"workspace.churn_zero.site_feed_table\")\n",
    "\n",
    "print(\"✅ Arquivo 'site_data.csv' gerado e tabela 'site_feed_table' atualizada!\")\n",
    "print(\"Squad B pode usar esses dados no Streamlit agora.\")\n",
    "display(df_app.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d953a67a-9fa8-4cba-b041-316a00de6513",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765152444512}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "USE workspace.churn_zero;\n",
    "SELECT\n",
    "  feedback_topic,\n",
    "  churn_probability,\n",
    "  priority_score\n",
    "FROM \n",
    "  site_feed_table\n",
    "ORDER BY \n",
    "  priority_score DESC"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8743201823108533,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "post_processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
